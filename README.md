# LLM Pretrain

## Summarize
> 1. PROCESSING Datasets 
> 2. MAIN Logic
> 3. AFTER Process

## PREPARE Datasets
Source of Dataset: Harry Potter from Kaggle

### LIBRARY
1. re
2. clean-text
3. panda

### Clean-text
No function, remove the line-break.

### re
Cleaning Data Text

## MainLogic
aa
### Tokenize & DataLoader
### TikTokenizer
good for eng

### DataLoader
#### Input & Target
Input에 따른 Target 값을 추측하게 만든다.


## AFTER Process
### Losses Graph
![훈련 손실 그래프](images/loss.png)

--- 
Github: 

## Sources
### Main
https://github.com/HongLabInc/HongLabLLM/blob/main/01_pretraining.ipynb
https://www.youtube.com/watch?v=osv2csoHVAo&t=724s

### Dataset Splitting
https://pozalabs.github.io/Dataset_Splitting/
